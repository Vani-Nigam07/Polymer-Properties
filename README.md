# **Next Best Action (NBA) Engine for Twitter Customer Support**

This repository hosts a complete end-to-end **Next Best Action Engine** designed to enhance customer service on Twitter. It reads real customer support interactions, analyzes user behavior, and generates intelligent response strategies using an LLM-based decision engine.

---

## **ğŸ“¦ Dataset**

We use the [Twitter Customer Support Dataset (TWSC)](https://www.kaggle.com/datasets/thoughtvector/customer-support-on-twitter/data) from Kaggle. It contains:
- Tweet threads between customers and brands
- Timestamps and message directions
- Metadata useful for conversation flow extraction

### **ğŸ—‚ï¸ Place raw dataset:**
Download the `twcs.csv` file and place it in:

```

data/raw/twcs.csv

```

This is your starting point for the ingestion pipeline.

---

## **ğŸš€ Project Structure**

```

Riverline\_NBA\_System/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                 # Raw CSV file (twcs.csv or new\_tweets.csv)
â”‚   â””â”€â”€ processed/           # SQLite DB containing normalized tweets
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ components/          # Modular logic for ingestion, NLP tagging, clustering
â”‚   â”œâ”€â”€ models/              # Model loading: SBERT, ZSC, Sentiment, LLM
â”‚   â”œâ”€â”€ pipeline/            # Modular pipelines for ingestion, processing, NBA engine
â”‚   â”œâ”€â”€ utils/
â”‚
â”œâ”€â”€ notebooks/              # 3 notebooks to walk through dev process
â”‚   â”œâ”€â”€ 1\_ingestion\_pipeline\_dev.ipynb
â”‚   â”œâ”€â”€ 2\_behavior\_analysis\_dev.ipynb
â”‚   â””â”€â”€ 3\_nba\_engine\_dev.ipynb
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ json/               # Parsed + tagged + NBA updated conversations
â”‚   â”œâ”€â”€ csv/                # Cluster tables, chat logs, NBA outputs
â”‚
â”œâ”€â”€ main.py                # FastAPI app for submitting new tweets
â”œâ”€â”€ config.yaml            # Config file for paths and DB settings
â””â”€â”€ requirements.txt       # Python dependencies

```

---

## **ğŸ§© How It Works**

### **ğŸ’¡ Core Idea**

This system simulates a smart **Customer Support Agent** that understands:
- Customer sentiment & urgency
- Issue type and resolution flow
- Ideal channel & timing for next action

It then **generates actionable replies** (DM, email, or phone) using LLMs with structured reasoning.

---

### **âš™ï¸ Modular Pipeline Architecture**

I split the pipeline into 3 clear stages:

#### 1ï¸âƒ£ Ingestion Pipeline
- Reads new tweets from CSV
- Filters out resolved customers (if any)
- Normalizes them into structured tables (SQLite)
- Output: `new_raw_tweets` and `new_interaction_table`

#### 2ï¸âƒ£ User Behavior Analysis
- Groups tweets into conversations
- Tags fine-grained issues using Zero-Shot Classification (ZSC)
- Tags sentiment, detects trajectory (worsening/improving)
- Clusters conversation flows using `BERTopic`

#### 3ï¸âƒ£ NBA Engine
- Loads conversation summary + flow
- Prompts a **LLM (LLaMA3 via Ollama)** to reason:
  - Best channel (DM / Email / Phone)
  - Best time to respond (UTC)
  - Best response message
  - Whether issue is resolved
- Stores results in:
  - `nba_actions_log.csv`
  - Appends agent reply to raw tweets â†’ re-ingested

---

## **ğŸ§ª Notebooks (Highly Recommended)**

To understand the full pipeline logic and model building:

1. `notebooks/01_data_ingestion.ipynb`
2. `notebooks/02_user_behavior.ipynb`
3. `notebooks/3_nba_engine.ipynb`

These walk through the development process of each module.

---

## **ğŸ§ª How to Run**

### **ğŸ”§ 1. Install Requirements**
```
pip install -r requirements.txt
````

Make sure to also install and run **Ollama** locally for the LLaMA model:

```
ollama run llama3
```

### **ğŸ§µ 2. Submit a Tweet via FastAPI**

Launch the FastAPI server:

```
uvicorn main:app --reload
```

Visit [http://127.0.0.1:8000/docs](http://127.0.0.1:8000/docs) to access Swagger UI and test:

#### **Example Request:**

```
POST /submit_tweet/
{
  "author_id": "user123",
  "text": "I can't reset my password!",
  "in_response_to_tweet_id": "NA",
  "response_tweet_id": "NA"
}
```

This will:

1. Append the tweet to `new_raw_tweets.csv`
2. Trigger all 3 pipelines in order
3. Inject agent's NBA reply and re-normalize tables

---

## **ğŸ› ï¸ Key Models & Techniques Used**

| Component                | Model / Tool                     |
| ------------------------ | -------------------------------- |
| Sentiment Tagging        | FinBERT                          |
| Zero-Shot Classification | BART-MNLI                        |
| Embedding Model          | SBERT (E5)                       |
| Flow Clustering          | BERTopic                         |
| LLM for NBA Decisions    | LLaMA 3 (via Ollama)             |
| Structured Reasoning     | LangChain StructuredOutputParser |

---

## **ğŸ”® Future Development**

### âœ… Next Goals:

* âš™ï¸ **MLOps Level 1** Automation using [**Airflow DAGs**](https://airflow.apache.org/) via **Astro CLI**
* ğŸ‘¤ Add **MTBI-based Persona Tagging** to personalize responses further
* ğŸ” Automate retraining or rule updates based on feedback loop

